{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QFjc8nS6ctJW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv('/content/block.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset"
      ],
      "metadata": {
        "id": "Ry-cfpeZ_6ma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping rows with any missing values\n",
        "data_dropped = data.dropna()\n",
        "\n",
        "# Filling the remaining missing values with a specific value, for example, filling NaNs with 0\n",
        "data_processed = data_dropped.fillna(0)\n",
        "\n",
        "# Displaying the processed data\n",
        "print(data_processed.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y99cmqnElnHH",
        "outputId": "c0db467b-655b-47e3-8188-acd54341b8b9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  member_name                     email  gender   location   employer  \\\n",
            "0       Chipi        ajimmison0@sun.com  female     Kwekwe       Vipe   \n",
            "1       Femba     rsoonhouse1@google.it  female  Marondera       Mudo   \n",
            "2        Geta  bchecchetelli2@house.gov  female     Rusape     Skaboo   \n",
            "3    Tichaona          mgarman3@psu.edu  female     Rusape  Babbleset   \n",
            "4       Chisa     ccough4@biglobe.ne.jp  female   Bulawayo   Flipopia   \n",
            "\n",
            "  relationship patient_name  patient_suffix patient_dob  \\\n",
            "0  Grandfather      Mabhena             789  09-11-1997   \n",
            "1      Husband      Sithole             860   1/14/1992   \n",
            "2       Mother        Chipi             374  07-03-1999   \n",
            "3       Father       Jembwa             729   7/31/1978   \n",
            "4       Father         Foto             716  12/28/1992   \n",
            "\n",
            "                   cause  Fee_Charged  membership_period  number_of_claims  \\\n",
            "0                  Other         3798               1541                 2   \n",
            "1                  Other        48905               8269                 4   \n",
            "2  Road Traffic Accident        39963               6223                 2   \n",
            "3  Road Traffic Accident        34948               8832                 6   \n",
            "4       Accident At Work        46984               8804                 1   \n",
            "\n",
            "   number_of_dependants  label  \n",
            "0                     4      0  \n",
            "1                     3      0  \n",
            "2                     2      0  \n",
            "3                     3      0  \n",
            "4                     2      1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Extraction using PCA"
      ],
      "metadata": {
        "id": "ZP75F4Zg_zlq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "id": "MJcV_eQinUsL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the numeric columns for feature extraction\n",
        "numeric_columns = ['patient_suffix','Fee_Charged','membership_period','number_of_claims','number_of_dependants','label']\n",
        "\n",
        "# Select the numeric columns for feature extraction\n",
        "X = data[numeric_columns]\n",
        "\n",
        "# Apply feature scaling\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Apply PCA for dimensionality reduction\n",
        "num_components = 5\n",
        "pca = PCA(n_components=num_components)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "\n",
        "# Create a DataFrame with the extracted PCA features\n",
        "pca_columns = [f'PCA_{i+1}' for i in range(num_components)]\n",
        "pca_df = pd.DataFrame(data=X_pca, columns=pca_columns)\n",
        "\n",
        "# Define meaningful names for the actual columns\n",
        "actual_column_names = ['patient_suffix','Fee_Charged','membership_period','number_of_claims','number_of_dependants','label']\n",
        "\n",
        "# Define the mapping of PCA feature columns to actual names based on their index\n",
        "pca_feature_mapping = {\n",
        "    pca_columns[i]: actual_column_names[i] + '_PCA' for i in range(num_components)\n",
        "}\n",
        "\n",
        "\n",
        "pca_df.rename(columns=pca_feature_mapping, inplace=True)\n",
        "\n",
        "final_df_with_actual_names = pd.concat([data, pca_df], axis=1)\n",
        "\n",
        "print(\"Final DataFrame with actual column names for PCA features:\")\n",
        "print(final_df_with_actual_names.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30F0jz66nQxR",
        "outputId": "2bb6e51e-de07-43b3-f140-2435240639c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final DataFrame with actual column names for PCA features:\n",
            "  member_name                     email  gender   location   employer  \\\n",
            "0       Chipi        ajimmison0@sun.com  female     Kwekwe       Vipe   \n",
            "1       Femba     rsoonhouse1@google.it  female  Marondera       Mudo   \n",
            "2        Geta  bchecchetelli2@house.gov  female     Rusape     Skaboo   \n",
            "3    Tichaona          mgarman3@psu.edu  female     Rusape  Babbleset   \n",
            "4       Chisa     ccough4@biglobe.ne.jp  female   Bulawayo   Flipopia   \n",
            "\n",
            "  relationship patient_name  patient_suffix patient_dob  \\\n",
            "0  Grandfather      Mabhena             789  09-11-1997   \n",
            "1      Husband      Sithole             860   1/14/1992   \n",
            "2       Mother        Chipi             374  07-03-1999   \n",
            "3       Father       Jembwa             729   7/31/1978   \n",
            "4       Father         Foto             716  12/28/1992   \n",
            "\n",
            "                   cause  Fee_Charged  membership_period  number_of_claims  \\\n",
            "0                  Other         3798               1541                 2   \n",
            "1                  Other        48905               8269                 4   \n",
            "2  Road Traffic Accident        39963               6223                 2   \n",
            "3  Road Traffic Accident        34948               8832                 6   \n",
            "4       Accident At Work        46984               8804                 1   \n",
            "\n",
            "   number_of_dependants  label  patient_suffix_PCA  Fee_Charged_PCA  \\\n",
            "0                     4      0           -2.470795         0.533099   \n",
            "1                     3      0            0.670615        -0.188674   \n",
            "2                     2      0            1.066120         0.752910   \n",
            "3                     3      0            0.300790        -1.102002   \n",
            "4                     2      1            2.345037         0.717004   \n",
            "\n",
            "   membership_period_PCA  number_of_claims_PCA  number_of_dependants_PCA  \n",
            "0               0.586079             -0.624312                  0.261783  \n",
            "1              -0.918131             -1.077263                 -1.221584  \n",
            "2              -0.954638             -0.362938                 -0.369856  \n",
            "3              -1.221016             -0.068508                 -0.502278  \n",
            "4               0.553252             -2.008591                  0.636738  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature selection using RFE"
      ],
      "metadata": {
        "id": "yJp-8l92_swQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Assuming 'final_df_with_actual_names' contains the DataFrame after PCA and feature concatenation\n",
        "\n",
        "# Extract only numeric columns for feature selection\n",
        "numeric_columns = final_df_with_actual_names.select_dtypes(include=['float64', 'int64']).columns\n",
        "features = final_df_with_actual_names[numeric_columns]\n",
        "\n",
        "# Remove the target column from features if it's included\n",
        "target_column = 'label'\n",
        "if target_column in features:\n",
        "    features = features.drop(columns=[target_column])\n",
        "\n",
        "# Initialize the model for feature selection (Random Forest Classifier)\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Initialize Recursive Feature Elimination (RFE)\n",
        "num_features_to_select = 3  # Number of features to select\n",
        "rfe = RFE(model, n_features_to_select=num_features_to_select)\n",
        "\n",
        "# Fit RFE to the data\n",
        "rfe.fit(features, final_df_with_actual_names[target_column])\n",
        "\n",
        "# Get the selected features\n",
        "selected_features = features.columns[rfe.support_]\n",
        "\n",
        "selected_features_data = final_df_with_actual_names[selected_features]\n",
        "\n",
        "# Print selected features along with their values\n",
        "print(selected_features_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbRC2_V9pofp",
        "outputId": "f5b31058-aa5f-47af-cab8-0eebb691a8a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      patient_suffix_PCA  membership_period_PCA  number_of_dependants_PCA\n",
            "0              -2.470795               0.586079                  0.261783\n",
            "1               0.670615              -0.918131                 -1.221584\n",
            "2               1.066120              -0.954638                 -0.369856\n",
            "3               0.300790              -1.221016                 -0.502278\n",
            "4               2.345037               0.553252                  0.636738\n",
            "...                  ...                    ...                       ...\n",
            "6995           -0.244741              -0.810280                 -0.038120\n",
            "6996            0.719844               0.293486                 -0.581801\n",
            "6997            0.553308              -0.867162                  0.200764\n",
            "6998            1.399607               0.291712                  1.412718\n",
            "6999           -0.984866              -0.161180                 -0.468776\n",
            "\n",
            "[7000 rows x 3 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-multiflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "308BBIJRsXQj",
        "outputId": "087c096b-dbe3-4bfe-caea-99b7c44203db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-multiflow in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
            "Requirement already satisfied: sortedcontainers>=1.5.7 in /usr/local/lib/python3.10/dist-packages (from scikit-multiflow) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from scikit-multiflow) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-multiflow) (1.11.3)\n",
            "Requirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-multiflow) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /usr/local/lib/python3.10/dist-packages (from scikit-multiflow) (1.2.2)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from scikit-multiflow) (1.5.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->scikit-multiflow) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20->scikit-multiflow) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=2.0.0->scikit-multiflow) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AdaBoost"
      ],
      "metadata": {
        "id": "Dfn3xruG_ntA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, mean_absolute_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Splitting data into features and target\n",
        "X = final_df_with_actual_names[selected_features]\n",
        "y = final_df_with_actual_names['label']\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "tree_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Initialize AdaBoost with DecisionTree as base classifier\n",
        "adaboost_classifier = AdaBoostClassifier(base_estimator=tree_classifier, n_estimators=50, learning_rate=1.0)\n",
        "\n",
        "# Train the classifier\n",
        "adaboost_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the trained AdaBoost classifier\n",
        "predictions = adaboost_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Calculate Sensitivity and Specificity from the confusion matrix (assuming binary classification)\n",
        "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
        "\n",
        "sensitivity = true_positives / (true_positives + false_negatives)\n",
        "specificity = true_negatives / (true_negatives + false_positives)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE)\n",
        "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JYZGDfcJzPGx",
        "outputId": "ed54d26e-7ad2-413a-aa5b-38c6601b068d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.995\n",
            "Sensitivity: 0.9851301115241635\n",
            "Specificity: 0.9973474801061007\n",
            "Root Mean Squared Error (RMSE): 0.07071067811865475\n",
            "Mean Absolute Error (MAE): 0.005\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### DecisionTree"
      ],
      "metadata": {
        "id": "tmR7liSK_dyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Splitting data into features and target\n",
        "X = final_df_with_actual_names[selected_features]\n",
        "y = final_df_with_actual_names['label']\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Decision Tree classifier\n",
        "tree_classifier = DecisionTreeClassifier()\n",
        "\n",
        "# Train the classifier\n",
        "tree_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the trained Decision Tree classifier\n",
        "predictions = tree_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Calculate Sensitivity and Specificity from the confusion matrix (assuming binary classification)\n",
        "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
        "\n",
        "sensitivity = true_positives / (true_positives + false_negatives)\n",
        "specificity = true_negatives / (true_negatives + false_positives)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE)\n",
        "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnBL5kLV58x3",
        "outputId": "eb3770bf-e8d6-4ee6-8e85-7d645ecdae2f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9942857142857143\n",
            "Sensitivity: 0.9851301115241635\n",
            "Specificity: 0.9964633068081344\n",
            "Root Mean Squared Error (RMSE): 0.07559289460184544\n",
            "Mean Absolute Error (MAE): 0.005714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GaussianNB"
      ],
      "metadata": {
        "id": "REnpYU_n_bYw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, mean_absolute_error\n",
        "\n",
        "\n",
        "# Splitting data into features and target\n",
        "X = final_df_with_actual_names[selected_features]\n",
        "y = final_df_with_actual_names['label']\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Gaussian Naive Bayes classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the trained Naive Bayes classifier\n",
        "predictions = nb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Calculate Sensitivity and Specificity from the confusion matrix (assuming binary classification)\n",
        "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
        "\n",
        "sensitivity = true_positives / (true_positives + false_negatives)\n",
        "specificity = true_negatives / (true_negatives + false_positives)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE)\n",
        "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnUHTLDR6428",
        "outputId": "71bb59aa-4d8e-4480-dd7d-7ae7f1ff5a0b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9978571428571429\n",
            "Sensitivity: 0.9888475836431226\n",
            "Specificity: 1.0\n",
            "Root Mean Squared Error (RMSE): 0.04629100498862757\n",
            "Mean Absolute Error (MAE): 0.002142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iuUYdU7w_Vha"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GradientBoosting"
      ],
      "metadata": {
        "id": "xZLkKz81_Xyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Assuming 'final_df_with_actual_names' contains the DataFrame after PCA and feature concatenation\n",
        "# Assuming 'selected_features' contains the selected features for modeling\n",
        "# Assuming 'label' is the target column\n",
        "\n",
        "# Splitting data into features and target\n",
        "X = final_df_with_actual_names[selected_features]\n",
        "y = final_df_with_actual_names['label']\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize Gradient Boosting classifier\n",
        "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Train the classifier\n",
        "gb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the trained Gradient Boosting classifier\n",
        "predictions = gb_classifier.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Calculate Sensitivity and Specificity from the confusion matrix (assuming binary classification)\n",
        "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
        "\n",
        "sensitivity = true_positives / (true_positives + false_negatives)\n",
        "specificity = true_negatives / (true_negatives + false_positives)\n",
        "\n",
        "# Calculate Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE)\n",
        "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-WeCTrp83AL",
        "outputId": "0e298f36-b943-4689-8f0f-d28ef861b093"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9992857142857143\n",
            "Sensitivity: 0.9962825278810409\n",
            "Specificity: 1.0\n",
            "Root Mean Squared Error (RMSE): 0.02672612419124244\n",
            "Mean Absolute Error (MAE): 0.0007142857142857143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ensemble Model"
      ],
      "metadata": {
        "id": "8CAAi1Eh_SBp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Splitting data into features and target\n",
        "X = final_df_with_actual_names[selected_features]\n",
        "y = final_df_with_actual_names['label']\n",
        "\n",
        "# Splitting the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize individual classifiers\n",
        "ada_classifier = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(max_depth=1), n_estimators=100, random_state=42)\n",
        "dt_classifier = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "gnb_classifier = GaussianNB()\n",
        "gb_classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "\n",
        "# Create a voting ensemble using the individual classifiers\n",
        "voting_classifier = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('AdaBoost', ada_classifier),\n",
        "        ('DecisionTree', dt_classifier),\n",
        "        ('GaussianNB', gnb_classifier),\n",
        "        ('GradientBoosting', gb_classifier)\n",
        "    ],\n",
        "    voting='hard'  # 'hard' voting takes the majority of votes, 'soft' voting computes the argmax of the sums of predicted probabilities\n",
        ")\n",
        "\n",
        "# Train the voting ensemble\n",
        "voting_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict using the trained voting ensemble\n",
        "predictions = voting_classifier.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_test, predictions)\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "true_negatives, false_positives, false_negatives, true_positives = conf_matrix.ravel()\n",
        "sensitivity = true_positives / (true_positives + false_negatives)\n",
        "specificity = true_negatives / (true_negatives + false_positives)\n",
        "rmse = mean_squared_error(y_test, predictions, squared=False)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "\n",
        "print(\"Metrics for Voting Classifier:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "print(\"Specificity:\", specificity)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKIfukCy9W8c",
        "outputId": "6f31a818-36de-4635-c279-21404f9f4927"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_base.py:166: FutureWarning: `base_estimator` was renamed to `estimator` in version 1.2 and will be removed in 1.4.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metrics for Voting Classifier:\n",
            "Accuracy: 0.9985714285714286\n",
            "Sensitivity: 0.9925650557620818\n",
            "Specificity: 1.0\n",
            "Root Mean Squared Error (RMSE): 0.03779644730092272\n",
            "Mean Absolute Error (MAE): 0.0014285714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confusion Matrix"
      ],
      "metadata": {
        "id": "z9re5Sbs__HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, predictions)\n",
        "\n",
        "# Plotting confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "BBBy7fkn-Ufa",
        "outputId": "a6f8e54d-87ba-4360-eef5-85d7b3d9fdee"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JnUmxTDk_Pg9"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}